{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "557585c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ebd1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 제곱 오차\n",
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9afd4dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09750000000000003\n",
      "0.5975\n"
     ]
    }
   ],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(sum_squares_error(np.array(y), np.array(t)))\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(sum_squares_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4397e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차 엔트로피 오차\n",
    "def cross_entropy_error(y, t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y+delta))\n",
    "\n",
    "# log(0)은 inf기 때문에 임의의 작은 값 delta를 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77b60cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.510825457099338\n",
      "2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))\n",
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "print(cross_entropy_error(np.array(y), np.array(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f04174e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label = True)\n",
    "print(x_train.shape)\n",
    "print(t_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "462a5161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:  60000\n",
      "[14905 43276 36564 19226 10053 22303  7714 52253   815 49672]\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "print(\"train_size: \", train_size)\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "print(batch_mask)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "print(len(x_batch))\n",
    "print(len(t_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da2b6189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#배치용 교차 엔트로피 구현\n",
    "def cross_entropy_error(y, t):\n",
    "    if y.dim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t*np.log(y+ 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6297e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원 핫 인코딩이 아닌 숫자 레이블로 주어졌을 때 엔트로피 오차\n",
    "def cross_entropy_error(y,t):\n",
    "    if y.dim == 1:\n",
    "        t = t.reshape(1,t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64c874",
   "metadata": {},
   "source": [
    "### 수지해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e0e46bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d83a2ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7d4b96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa104e6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1999999999990898\n",
      "0.2999999999986347\n"
     ]
    }
   ],
   "source": [
    "print(numerical_diff(function_1, 5))\n",
    "print(numerical_diff(function_1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e456b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce97269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사 하강법\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb421ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x=init_x, lr=0.1, step_num=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49be7243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#학습률이 너무 큰 경우\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x =init_x, lr=10.0, step_num =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2286270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습률이 너무 작은 경우\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "gradient_descent(function_2, init_x =init_x, lr=1e-10, step_num=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe735b",
   "metadata": {},
   "source": [
    "### 신경망에서의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1377e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ae5e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b79e152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.59403114  0.36981512 -0.92585671]\n",
      " [ 0.85497708  0.74506903 -0.74845305]]\n",
      "[ 1.12589806  0.8924512  -1.22912177]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)\n",
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c85ecea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea94666b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.989842494898648"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0, 0, 1])\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b48b47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87a3add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31801642  0.2518053  -0.56982171]\n",
      " [ 0.47702463  0.37770794 -0.85473257]]\n"
     ]
    }
   ],
   "source": [
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e88c955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.31801642  0.2518053  -0.56982171]\n",
      " [ 0.47702463  0.37770794 -0.85473257]]\n"
     ]
    }
   ],
   "source": [
    "f = lambda w: net.loss(x, t)\n",
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2453837",
   "metadata": {},
   "source": [
    "### 학습 알고리즘 구현하기\n",
    "<br>\n",
    "1단계 - 미니배치<br>\n",
    "    훈련 데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며, 그 미니배치의 손실 함수 값을 줄이는 것이 목표다.<br>\n",
    "2단계 - 기울기 산출<br>\n",
    "    미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게하는 방향을 제시한다.<br>\n",
    "3단계 - 배개변수 갱신<br>\n",
    "    가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다.<br>\n",
    "4단계 - 반복<br>\n",
    "    1~3단계를 반복한다<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0f98e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2층 신경망 클래스 구현하기\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis = 1)\n",
    "        t = np.argmax(t, axis = 1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params[\"W1\"])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params[\"b1\"])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params[\"W2\"])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params[\"b2\"])\n",
    "        \n",
    "        return grads\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c733420b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "net = TwoLayerNet(input_size = 784, hidden_size=100, output_size=10)\n",
    "print(net.params['W1'].shape)\n",
    "print(net.params['b1'].shape)\n",
    "print(net.params['W2'].shape)\n",
    "print(net.params['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1fbfda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "[[0.10517329 0.09655005 0.10708122 0.10185137 0.10095238 0.09374385\n",
      "  0.10327021 0.09700945 0.09954143 0.09482677]\n",
      " [0.10529966 0.09644103 0.10721016 0.10195998 0.10104354 0.09343522\n",
      "  0.10333942 0.09682056 0.09972326 0.09472719]\n",
      " [0.10521838 0.09683181 0.10688353 0.10148775 0.1007895  0.09349906\n",
      "  0.10297593 0.09724771 0.09965516 0.09541117]\n",
      " [0.10508407 0.09674205 0.1072756  0.10173503 0.10062415 0.09335248\n",
      "  0.10311791 0.09722392 0.0998183  0.09502648]\n",
      " [0.10509249 0.09660297 0.10708757 0.10157082 0.10078007 0.09340246\n",
      "  0.10342802 0.09729606 0.09980062 0.09493893]\n",
      " [0.1052415  0.09662536 0.10730772 0.10139017 0.10106352 0.09335904\n",
      "  0.10331274 0.09707844 0.09968404 0.09493747]\n",
      " [0.10522631 0.09668528 0.10745675 0.10176603 0.10099099 0.09303036\n",
      "  0.10312753 0.09701919 0.09953072 0.09516683]\n",
      " [0.10526605 0.09693569 0.10717973 0.10143048 0.10094843 0.09329698\n",
      "  0.10296351 0.09734943 0.09947423 0.09515546]\n",
      " [0.1055984  0.09648774 0.1069502  0.10178284 0.10094032 0.09325702\n",
      "  0.10297095 0.09715318 0.09971363 0.09514572]\n",
      " [0.10513968 0.09656494 0.10723076 0.1016473  0.10084785 0.09355499\n",
      "  0.10307057 0.09713364 0.09975738 0.09505291]\n",
      " [0.10529869 0.09690175 0.10742328 0.10136524 0.10065336 0.09318268\n",
      "  0.10321695 0.09716044 0.0996828  0.09511482]\n",
      " [0.10542978 0.0965351  0.1070872  0.1015165  0.10117579 0.09346816\n",
      "  0.10295225 0.09696907 0.09958309 0.09528305]\n",
      " [0.10536099 0.09669073 0.10712976 0.10166273 0.1009338  0.09345352\n",
      "  0.10324314 0.09686548 0.0994495  0.09521034]\n",
      " [0.10487187 0.09705719 0.1075674  0.10138364 0.10101545 0.09293658\n",
      "  0.10315341 0.09752089 0.09966734 0.09482624]\n",
      " [0.10558079 0.09668768 0.10709291 0.10189219 0.10075907 0.09333096\n",
      "  0.10293969 0.09682111 0.09961611 0.09527948]\n",
      " [0.10531565 0.09656551 0.10729507 0.10202895 0.10074194 0.09335726\n",
      "  0.10326373 0.09707085 0.09946209 0.09489894]\n",
      " [0.10550359 0.0964893  0.10724032 0.1016296  0.10117792 0.09337785\n",
      "  0.10321584 0.09677847 0.09927319 0.09531392]\n",
      " [0.10532049 0.0967658  0.10742323 0.10159042 0.10088681 0.09343946\n",
      "  0.10336525 0.09679628 0.0995689  0.09484336]\n",
      " [0.10549385 0.09642743 0.10696906 0.10192671 0.10085568 0.09310345\n",
      "  0.10286846 0.09736097 0.09966838 0.09532601]\n",
      " [0.10541881 0.09623078 0.10712964 0.10191716 0.10116259 0.09329949\n",
      "  0.10292128 0.09705251 0.09947195 0.09539579]\n",
      " [0.10509078 0.09685725 0.10733711 0.1018907  0.10096528 0.0935795\n",
      "  0.10279324 0.09701399 0.09964324 0.0948289 ]\n",
      " [0.10525148 0.09686793 0.10718741 0.1013832  0.10063914 0.09350494\n",
      "  0.10315194 0.09737105 0.09957164 0.09507128]\n",
      " [0.10512469 0.09623433 0.10711877 0.10180356 0.1011666  0.09331791\n",
      "  0.10322545 0.09681991 0.09980515 0.09538361]\n",
      " [0.1054962  0.09639265 0.10712313 0.10191841 0.10073568 0.09365172\n",
      "  0.10308906 0.09692215 0.09966961 0.0950014 ]\n",
      " [0.1051666  0.09667941 0.10724372 0.10160695 0.10075021 0.09339175\n",
      "  0.10306139 0.09725147 0.09975041 0.09509809]\n",
      " [0.10509862 0.09671761 0.10743173 0.10174526 0.10060502 0.09343505\n",
      "  0.10283617 0.09745388 0.09957917 0.09509749]\n",
      " [0.10501906 0.09671787 0.10697749 0.10204537 0.10102624 0.09316443\n",
      "  0.10323958 0.09724295 0.09966827 0.09489873]\n",
      " [0.10505829 0.09637218 0.1073817  0.10159445 0.10109014 0.09350778\n",
      "  0.10305587 0.09695327 0.09970404 0.09528227]\n",
      " [0.10509782 0.09701887 0.10692392 0.10203464 0.10088064 0.09323779\n",
      "  0.10323912 0.09684987 0.09953049 0.09518684]\n",
      " [0.10554674 0.0968109  0.10737102 0.10181915 0.10083951 0.09351806\n",
      "  0.10319521 0.09668709 0.09929426 0.09491805]\n",
      " [0.10549833 0.09641476 0.10711897 0.10190068 0.10094351 0.09347588\n",
      "  0.10334275 0.09687283 0.09942249 0.0950098 ]\n",
      " [0.10516707 0.0967521  0.107151   0.10141679 0.10101249 0.09323872\n",
      "  0.10331088 0.09718495 0.09953072 0.09523529]\n",
      " [0.10545886 0.09647847 0.10740848 0.10157897 0.10107709 0.0932383\n",
      "  0.10322268 0.09696114 0.09968818 0.09488783]\n",
      " [0.10547449 0.09628539 0.10702524 0.10217341 0.1006375  0.09340833\n",
      "  0.10349098 0.09696034 0.09960527 0.09493907]\n",
      " [0.1051643  0.09647349 0.10720063 0.10192161 0.10087814 0.09362928\n",
      "  0.10342493 0.09699237 0.09937864 0.0949366 ]\n",
      " [0.10508101 0.09657917 0.10708377 0.10217637 0.1008811  0.09320591\n",
      "  0.10339466 0.09698595 0.09945413 0.09515793]\n",
      " [0.10539998 0.09680471 0.10715064 0.10144109 0.10054326 0.09358767\n",
      "  0.10319322 0.09723861 0.09939393 0.09524689]\n",
      " [0.10524876 0.09626022 0.10677289 0.10217117 0.10073939 0.09337367\n",
      "  0.103314   0.09728304 0.09947783 0.09535902]\n",
      " [0.10520034 0.09654423 0.10720162 0.10162724 0.10087731 0.09317591\n",
      "  0.10296112 0.09716558 0.09991232 0.09533434]\n",
      " [0.10536327 0.09668424 0.10721107 0.10171591 0.10077962 0.09352052\n",
      "  0.1031308  0.0968476  0.09962988 0.09511708]\n",
      " [0.105181   0.0967924  0.10716761 0.10164865 0.10106067 0.09360331\n",
      "  0.10326442 0.09717094 0.0994003  0.09471069]\n",
      " [0.10526239 0.09652741 0.10685702 0.10197884 0.10110388 0.0934568\n",
      "  0.10304901 0.09703444 0.09953264 0.09519757]\n",
      " [0.10545662 0.09669692 0.1073342  0.1019095  0.1008345  0.09326351\n",
      "  0.10312962 0.09692623 0.09945132 0.09499758]\n",
      " [0.10532391 0.09671969 0.10720306 0.10177569 0.10096419 0.09346923\n",
      "  0.10276726 0.0968801  0.09951861 0.09537827]\n",
      " [0.10573115 0.09655208 0.10726547 0.10179511 0.10040448 0.09353188\n",
      "  0.1032353  0.09697971 0.09953961 0.09496521]\n",
      " [0.10555108 0.09665049 0.10735904 0.10188182 0.10077218 0.09331924\n",
      "  0.10303609 0.09679528 0.09975655 0.09487824]\n",
      " [0.1052511  0.09627752 0.10711764 0.10180908 0.10115743 0.09343699\n",
      "  0.10318905 0.09698428 0.09953946 0.09523744]\n",
      " [0.10503765 0.09663943 0.10719855 0.10176823 0.10087946 0.0936601\n",
      "  0.10326372 0.09700902 0.09935568 0.09518817]\n",
      " [0.10515998 0.09675738 0.10741144 0.10180831 0.10068111 0.09361551\n",
      "  0.10315555 0.09705695 0.09958174 0.09477203]\n",
      " [0.10533592 0.09674004 0.10721863 0.10153726 0.10110729 0.09335234\n",
      "  0.10307112 0.09673514 0.09962195 0.09528031]\n",
      " [0.10496156 0.0966065  0.10737254 0.10220422 0.10084443 0.09333277\n",
      "  0.10289417 0.09704933 0.099675   0.09505948]\n",
      " [0.10492973 0.09634651 0.10710172 0.101591   0.10100376 0.09349688\n",
      "  0.10326917 0.09717906 0.09975052 0.09533165]\n",
      " [0.10527113 0.0965784  0.10734025 0.10164689 0.10075023 0.09316341\n",
      "  0.10314039 0.0969857  0.09954947 0.09557413]\n",
      " [0.10531785 0.09673713 0.10692196 0.10160257 0.10105792 0.09337448\n",
      "  0.10313343 0.09700684 0.09937782 0.09547002]\n",
      " [0.10526506 0.09663138 0.10746402 0.10188076 0.10083266 0.09361975\n",
      "  0.10305053 0.09705956 0.09926371 0.09493257]\n",
      " [0.10523526 0.09646393 0.10722493 0.10187599 0.10101134 0.09350289\n",
      "  0.10278421 0.09728469 0.09944482 0.09517193]\n",
      " [0.10518637 0.09663255 0.10719198 0.10135227 0.10100793 0.09336653\n",
      "  0.10356367 0.09688355 0.09938219 0.09543296]\n",
      " [0.10509567 0.09660544 0.10701899 0.10195069 0.10091765 0.09321107\n",
      "  0.1029977  0.09734881 0.09944536 0.09540863]\n",
      " [0.10517802 0.09655479 0.10716279 0.10190273 0.10111068 0.09325688\n",
      "  0.1032641  0.09698181 0.09967602 0.09491216]\n",
      " [0.10557275 0.09641125 0.10696338 0.10194318 0.10099135 0.09328963\n",
      "  0.10307077 0.09692682 0.0997483  0.09508257]\n",
      " [0.10503246 0.09673881 0.10710476 0.10175329 0.10095258 0.09357296\n",
      "  0.10301896 0.09713327 0.09958192 0.095111  ]\n",
      " [0.10505314 0.09634142 0.10724761 0.10208799 0.10097646 0.09325839\n",
      "  0.10312036 0.09733761 0.09957863 0.09499837]\n",
      " [0.10502867 0.0969241  0.10718025 0.10184718 0.10103918 0.09335783\n",
      "  0.10287453 0.09724041 0.09932367 0.09518415]\n",
      " [0.10523161 0.0963626  0.10679769 0.10223573 0.10130925 0.09317351\n",
      "  0.1029334  0.09701305 0.0995744  0.09536875]\n",
      " [0.10529252 0.09648234 0.10689682 0.10162258 0.10081875 0.09375815\n",
      "  0.10327908 0.09713906 0.09938815 0.09532254]\n",
      " [0.10528435 0.09640662 0.10718974 0.10209795 0.10057839 0.09369439\n",
      "  0.10339604 0.09701316 0.09935569 0.09498366]\n",
      " [0.10536303 0.09677612 0.10705673 0.1012132  0.10092029 0.09350419\n",
      "  0.10348292 0.09709638 0.09931197 0.09527516]\n",
      " [0.10501447 0.09690728 0.10736005 0.10164822 0.10083193 0.09363048\n",
      "  0.10312157 0.09708829 0.09947468 0.09492303]\n",
      " [0.10555837 0.09658414 0.10714664 0.10187497 0.10075369 0.09367912\n",
      "  0.1030723  0.0970422  0.09943064 0.09485795]\n",
      " [0.10546011 0.09673492 0.10713921 0.10169185 0.10114578 0.09323328\n",
      "  0.10341039 0.09673825 0.09928559 0.09516063]\n",
      " [0.10518325 0.09657777 0.10701589 0.10196894 0.10098498 0.09361319\n",
      "  0.1031547  0.09687706 0.09953237 0.09509184]\n",
      " [0.10557058 0.09645742 0.10715233 0.10192957 0.10102394 0.09338347\n",
      "  0.10299433 0.09696799 0.09928363 0.09523673]\n",
      " [0.10517692 0.09669816 0.10712797 0.10176383 0.10097705 0.09325564\n",
      "  0.1030526  0.09742339 0.0992525  0.09527194]\n",
      " [0.10533812 0.09646652 0.10714178 0.10202272 0.10106237 0.09344395\n",
      "  0.10294758 0.09711373 0.09944385 0.09501938]\n",
      " [0.10548456 0.0965565  0.10757552 0.10156729 0.10084934 0.09344557\n",
      "  0.10267232 0.09730584 0.09962644 0.09491662]\n",
      " [0.10518507 0.09665815 0.10730033 0.10182522 0.10095202 0.09335277\n",
      "  0.10307282 0.09703793 0.09942857 0.09518712]\n",
      " [0.1055647  0.09651172 0.10686714 0.10183428 0.10097949 0.09321217\n",
      "  0.10296186 0.09741268 0.09942331 0.09523265]\n",
      " [0.10529203 0.09661796 0.10725028 0.10199595 0.100884   0.09317955\n",
      "  0.10304228 0.09714756 0.0994377  0.09515269]\n",
      " [0.10506106 0.09666491 0.10755765 0.10153769 0.10101366 0.09322838\n",
      "  0.10313771 0.09717944 0.09967168 0.09494783]\n",
      " [0.10548075 0.09647041 0.10725201 0.10156821 0.10093294 0.09329816\n",
      "  0.10345787 0.09673754 0.09939185 0.09541027]\n",
      " [0.10521937 0.09671355 0.10715825 0.10155218 0.10093246 0.09333486\n",
      "  0.10297586 0.09727067 0.09971363 0.09512918]\n",
      " [0.10525228 0.09673903 0.10696794 0.1017055  0.10102039 0.09338905\n",
      "  0.10320982 0.09704891 0.09939826 0.09526882]\n",
      " [0.10548473 0.09640268 0.10721101 0.10159713 0.10101239 0.09347967\n",
      "  0.10311742 0.09699452 0.09950896 0.09519149]\n",
      " [0.10561787 0.09683731 0.10714141 0.10150426 0.1006727  0.09354093\n",
      "  0.10318868 0.0971725  0.09960866 0.09471566]\n",
      " [0.10487319 0.09696262 0.10716737 0.10180069 0.10053286 0.09331518\n",
      "  0.10327702 0.09708565 0.09973924 0.09524617]\n",
      " [0.10536592 0.0966698  0.10730021 0.10181264 0.10080941 0.09344759\n",
      "  0.10327331 0.09711133 0.09912676 0.09508304]\n",
      " [0.10543792 0.0967204  0.10743387 0.10175651 0.10074098 0.09352227\n",
      "  0.10303942 0.09694192 0.09960969 0.09479702]\n",
      " [0.10520172 0.09653862 0.10710355 0.10187321 0.10080606 0.09303137\n",
      "  0.1031962  0.09713844 0.0996725  0.09543835]\n",
      " [0.10494884 0.09645766 0.10723342 0.10211291 0.10090177 0.09385733\n",
      "  0.10292991 0.09701765 0.09949571 0.09504479]\n",
      " [0.10520416 0.09660625 0.10747716 0.10155841 0.100773   0.09331742\n",
      "  0.10310781 0.09720912 0.0994867  0.09525997]\n",
      " [0.10519795 0.09672509 0.10718168 0.10195536 0.10099779 0.09337515\n",
      "  0.10277817 0.09681618 0.09969535 0.09527728]\n",
      " [0.1051274  0.0968461  0.10693621 0.10171622 0.10117415 0.09357221\n",
      "  0.10325239 0.09709064 0.09943475 0.09484993]\n",
      " [0.10556108 0.09635442 0.10731148 0.10155698 0.10076484 0.09338452\n",
      "  0.10356354 0.09705851 0.09943838 0.09500626]\n",
      " [0.10516438 0.09675483 0.10734527 0.10178121 0.10084238 0.09332785\n",
      "  0.10292576 0.09723348 0.09948454 0.0951403 ]\n",
      " [0.10560247 0.09637155 0.10698417 0.10168765 0.1009363  0.09331169\n",
      "  0.10306813 0.09704409 0.09994414 0.09504982]\n",
      " [0.10560131 0.09664336 0.10721671 0.10139111 0.1010243  0.09348126\n",
      "  0.10326888 0.09702617 0.0994178  0.09492909]\n",
      " [0.10519596 0.0962853  0.10721421 0.10201862 0.10105104 0.09334856\n",
      "  0.1031978  0.09713578 0.09966691 0.09488581]\n",
      " [0.10533312 0.09668322 0.10734774 0.10182622 0.10071046 0.09344792\n",
      "  0.10297988 0.09720651 0.09941105 0.09505387]\n",
      " [0.10528197 0.09680245 0.10682135 0.10148029 0.10117283 0.09316535\n",
      "  0.10330449 0.09723735 0.09941302 0.09532091]\n",
      " [0.10509442 0.09643809 0.10688315 0.10204806 0.10100363 0.0935102\n",
      "  0.10308224 0.09712563 0.09969253 0.09512206]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "print(x.shape)\n",
    "y = net.predict(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9104f1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 100)\n",
      "(100,)\n",
      "(100, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 784)\n",
    "t = np.random.rand(100, 10)\n",
    "\n",
    "grads = net.numerical_gradient(x, t)\n",
    "print(grads['W1'].shape)\n",
    "print(grads['b1'].shape)\n",
    "print(grads['W2'].shape)\n",
    "print(grads['b2'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bc746f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2481662668.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/39/2knbgcdd14xfvt_5n7_wl0dh0000gn/T/ipykernel_23918/2481662668.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    (x_train, t_train) , (x_test, t_test) = load_mnist(normalize=True, one_hot_label= = True)\u001b[0m\n\u001b[0m                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 미니배치 학습 구현\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train) , (x_test, t_test) = load_mnist(normalize=True, one_hot_label= = True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "lr = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=28*28, hidden_size=50, output_size=10)\n",
    "\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    \n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= lr * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10780cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
